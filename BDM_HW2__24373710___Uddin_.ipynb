{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2"
      ],
      "metadata": {
        "id": "gbF71GHptuwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "P_5RV35CtCaB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjzjcPWYnHLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b846af8-f331-4a96-9c19-6b3badc1cf44"
      },
      "source": [
        "%%shell\n",
        "gdown --quiet 1ay5DcH64Qao1HR7CQnR6Cl1hbBMgGqXj\n",
        "gdown --quiet 13BozEl3JtS43Xuu2Ek9IwMULpWjPH4VC\n",
        "gdown --quiet 1It6GP8O2JqkmUtZKbYp1kpwpuwOXlLps\n",
        "pip --quiet install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHKq10WXnZl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b10636e6-a933-4897-9f7f-7625a27ffbcb"
      },
      "source": [
        "SAT_FN = 'SAT_Results.csv'\n",
        "HSD_FN = 'DOE_High_School_Directory_2014-2015.csv'\n",
        "ENRON_FN = 'enron_mails_small.csv'\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "sc = pyspark.SparkContext.getOrCreate()\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fb8f4570610>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://96af0997abf8:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Ykp1Qqnu5f"
      },
      "source": [
        "## Task 1 (5 points)\n",
        "\n",
        "Your task is to do Task 2 of Lab 5 (see **`BDM_Lab05_Spark.pdf`**). Below is a step-by-step walkthrough of the solution using RDD (using the approach detailed in the hint file **`BDM_Lab05_Spark_Keys.pdf`). Please complete each sub-task that is marked with `[TO DO]` (step `D`, `E`, and `G`). For those cells without `[TO DO]`, you are expected to run it without any edits and without any error, with the provided output."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. Load **SAT Scores** Dataset without Header"
      ],
      "metadata": {
        "id": "Viwi27S1xMpV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "6_caGSrHpVJq",
        "outputId": "137fa6f3-6d5f-4cfd-9324-4ecddce8e1d5"
      },
      "source": [
        "# We read the SAT score to our RDD. Note that the use_unicode can be\n",
        "# changed accordingly to your data file to handle Unicode. If you cannot\n",
        "# parse your data due to an 'utf8' or 'ascii' decoding issue, it might\n",
        "# be a good thing to try flipping the use_unicode parameter here.\n",
        "\n",
        "sat = sc.textFile(SAT_FN, use_unicode=True).cache()\n",
        "satHeader = sat.first().split(',')\n",
        "A = sat.filter(lambda x: not x.startswith('DBN,SCHOOL'))\n",
        "\n",
        "# This line for us to list the column index and column names to see\n",
        "# which column we need to use for our task. In this case, we're\n",
        "# interested in the number of test takers (#2) and the math score (#4).\n",
        "display(list(enumerate(satHeader)))\n",
        "A.take(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[(0, 'DBN'),\n",
              " (1, 'SCHOOL NAME'),\n",
              " (2, 'Num of SAT Test Takers'),\n",
              " (3, 'SAT Critical Reading Avg. Score'),\n",
              " (4, 'SAT Math Avg. Score'),\n",
              " (5, 'SAT Writing Avg. Score')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['02M047,47 THE AMERICAN SIGN LANGUAGE AND ENGLISH SECONDARY SCHOOL,16,395,400,387',\n",
              " '21K410,ABRAHAM LINCOLN HIGH SCHOOL,475,396,437,393',\n",
              " '21K412/21K411,ABRAHAM LINCOLN YABC/LEARNING TO WORK GED AT ABRAHAM LINCOLN,s,s,s,s']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. Extract `DBN`, `Num of SAT Test Takers` and `SAT Math Avg. Score` columns\n",
        "\n",
        "Here is a different approach to read the SAT score file using `map()` instead of `mapPartitionsWithIndex()`. Please note the use of `csv.reader` with a single input line."
      ],
      "metadata": {
        "id": "foKWz_8Ay25v"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jem4hsNpfQr",
        "outputId": "56e242a3-ec2f-482f-8aba-8127ca36eb13"
      },
      "source": [
        "import csv\n",
        "\n",
        "B = A.map(lambda x: next(csv.reader([x]))) \\\n",
        "    .filter(lambda x: x[2]!='s') \\\n",
        "    .map(lambda x: (x[0], (int(x[2]), int(x[4]))))\n",
        "\n",
        "B.take(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('02M047', (16, 400)), ('21K410', (475, 437)), ('30Q301', (98, 440))]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C. Load **High School Directory** Dataset and check its header"
      ],
      "metadata": {
        "id": "a6yKREbm1Pjt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tuDGRXcphca",
        "outputId": "d28ecad2-ffff-411b-cce4-9bd550d96f1b"
      },
      "source": [
        "# Here we do the same thing with the school directory data\n",
        "C = sc.textFile(HSD_FN, use_unicode=True).cache()\n",
        "hsdHeader = C.first().split(',')\n",
        "list(enumerate(hsdHeader))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'dbn'),\n",
              " (1, 'school_name'),\n",
              " (2, 'boro'),\n",
              " (3, 'building_code'),\n",
              " (4, 'phone_number'),\n",
              " (5, 'fax_number'),\n",
              " (6, 'grade_span_min'),\n",
              " (7, 'grade_span_max'),\n",
              " (8, 'expgrade_span_min'),\n",
              " (9, 'expgrade_span_max'),\n",
              " (10, 'bus'),\n",
              " (11, 'subway'),\n",
              " (12, 'primary_address_line_1'),\n",
              " (13, 'city'),\n",
              " (14, 'state_code'),\n",
              " (15, 'zip'),\n",
              " (16, 'website'),\n",
              " (17, 'total_students'),\n",
              " (18, 'campus_name'),\n",
              " (19, 'school_type'),\n",
              " (20, 'overview_paragraph'),\n",
              " (21, 'program_highlights'),\n",
              " (22, 'language_classes'),\n",
              " (23, 'advancedplacement_courses'),\n",
              " (24, 'online_ap_courses'),\n",
              " (25, 'online_language_courses'),\n",
              " (26, 'extracurricular_activities'),\n",
              " (27, 'psal_sports_boys'),\n",
              " (28, 'psal_sports_girls'),\n",
              " (29, 'psal_sports_coed'),\n",
              " (30, 'school_sports'),\n",
              " (31, 'partner_cbo'),\n",
              " (32, 'partner_hospital'),\n",
              " (33, 'partner_highered'),\n",
              " (34, 'partner_cultural'),\n",
              " (35, 'partner_nonprofit'),\n",
              " (36, 'partner_corporate'),\n",
              " (37, 'partner_financial'),\n",
              " (38, 'partner_other'),\n",
              " (39, 'addtl_info1'),\n",
              " (40, 'addtl_info2'),\n",
              " (41, 'start_time'),\n",
              " (42, 'end_time'),\n",
              " (43, 'se_services'),\n",
              " (44, 'ell_programs'),\n",
              " (45, 'school_accessibility_description'),\n",
              " (46, 'number_programs'),\n",
              " (47, 'priority01'),\n",
              " (48, 'priority02'),\n",
              " (49, 'priority03'),\n",
              " (50, 'priority04'),\n",
              " (51, 'priority05'),\n",
              " (52, 'priority06'),\n",
              " (53, 'priority07'),\n",
              " (54, 'priority08'),\n",
              " (55, 'priority09'),\n",
              " (56, 'priority10'),\n",
              " (57, 'Location 1')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [TO DO] D. Extract `DBN`, `bus` and `subway` columns from the HSD data"
      ],
      "metadata": {
        "id": "ew1QtSG6EULL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0KjPdzRpkMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fe0870-a062-49f7-e21b-8a77e33711cc"
      },
      "source": [
        "# Complete the extractFeatures function to get the desire output\n",
        "def extractFeatures(partId, rows):\n",
        "    if partId==0:\n",
        "        next(rows) # avoiding header here\n",
        "    reader = csv.reader(rows)\n",
        "    for fields in reader:\n",
        "        if len(fields) < 12: # Solving index problem\n",
        "            continue\n",
        "        dbn, bus, subway = fields[0], fields[10], fields[11]\n",
        "        yield (dbn, bus, subway)\n",
        "\n",
        "### DO NOT EDIT BELOW\n",
        "D = C.mapPartitionsWithIndex(extractFeatures) \n",
        "D.take(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('01M292',\n",
              "  'B39, M14A, M14D, M15, M15-SBS, M21, M22, M9',\n",
              "  'B, D to Grand St ; F to East Broadway ; J, M, Z to Delancey St-Essex St'),\n",
              " ('01M448',\n",
              "  'M14A, M14D, M15, M21, M22, M9',\n",
              "  'F to East Broadway ; J, M, Z to Delancey St-Essex St'),\n",
              " ('01M450',\n",
              "  'M101, M102, M103, M14A, M14D, M15, M15-SBS, M2, M23, M3, M8, M9',\n",
              "  '6 to Astor Place ; L to 1st Ave'),\n",
              " ('01M509',\n",
              "  'B39, M103, M14A, M14D, M15, M15-SBS, M21, M22, M8, M9',\n",
              "  'B, D to Grand St ; F, J, M, Z to Delancey St-Essex St'),\n",
              " ('01M539',\n",
              "  'B39, M14A, M14D, M21, M22, M8, M9',\n",
              "  'F, J, M, Z to Delancey St-Essex St')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [TO DO] E. Convert the bus and subway description into the list of bus and subway lines\n",
        "\n",
        "For the subway, we do not care about the direction of the lines, e.g. `B, D to Grand St` should be treated as just `B, D`."
      ],
      "metadata": {
        "id": "boijlIy-FKUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ConvertBusSubway(i):\n",
        "    dbn, bus, subway = i\n",
        "    bus_lines = list(map(lambda x: x.strip(), bus.split(','))) #Splitting by comma\n",
        "    subway_lines = []\n",
        "    for line in subway.split(';'):\n",
        "        subway_lines.extend(list(map(lambda x: x.strip(), line.split('to')[0].split(',')))) #Splitting by comma & to\n",
        "    return (dbn, (bus_lines, subway_lines))\n",
        "\n",
        "# Derive E from above\n",
        "E = D.map(lambda i: ConvertBusSubway(i))\n",
        "\n",
        "### DO NOT EDIT BELOW\n",
        "E.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igGXWQDzFj8W",
        "outputId": "847c52f7-376a-4f10-927f-925c56bcfee7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('01M292',\n",
              "  (['B39', 'M14A', 'M14D', 'M15', 'M15-SBS', 'M21', 'M22', 'M9'],\n",
              "   ['B', 'D', 'F', 'J', 'M', 'Z'])),\n",
              " ('01M448',\n",
              "  (['M14A', 'M14D', 'M15', 'M21', 'M22', 'M9'], ['F', 'J', 'M', 'Z'])),\n",
              " ('01M450',\n",
              "  (['M101',\n",
              "    'M102',\n",
              "    'M103',\n",
              "    'M14A',\n",
              "    'M14D',\n",
              "    'M15',\n",
              "    'M15-SBS',\n",
              "    'M2',\n",
              "    'M23',\n",
              "    'M3',\n",
              "    'M8',\n",
              "    'M9'],\n",
              "   ['6', 'L'])),\n",
              " ('01M509',\n",
              "  (['B39', 'M103', 'M14A', 'M14D', 'M15', 'M15-SBS', 'M21', 'M22', 'M8', 'M9'],\n",
              "   ['B', 'D', 'F', 'J', 'M', 'Z'])),\n",
              " ('01M539',\n",
              "  (['B39', 'M14A', 'M14D', 'M21', 'M22', 'M8', 'M9'], ['F', 'J', 'M', 'Z']))]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F. Join `B` (SAT) and `E`(HSD) datasets so that the score is together with the list of bus lines and subway lines.\n",
        "\n",
        "We no longer need to the DBN information after this."
      ],
      "metadata": {
        "id": "jBQe55oMG4Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F = B.join(E).values()\n",
        "F.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJhzlRvuHKjT",
        "outputId": "f1977a5a-48cd-48af-8be1-416204a9751d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((59, 374),\n",
              "  (['B12', 'B16', 'B35', 'B41', 'B44', 'B49'], ['2', '5', 'B', 'Q'])),\n",
              " ((135, 492),\n",
              "  (['B62',\n",
              "    'Q100',\n",
              "    'Q101',\n",
              "    'Q102',\n",
              "    'Q103',\n",
              "    'Q32',\n",
              "    'Q39',\n",
              "    'Q60',\n",
              "    'Q66',\n",
              "    'Q67',\n",
              "    'Q69'],\n",
              "   ['7', 'N', 'Q', 'E', 'M', 'R', 'F', 'G'])),\n",
              " ((228, 456),\n",
              "  (['Bx15',\n",
              "    'Bx19',\n",
              "    'Bx33',\n",
              "    'M10',\n",
              "    'M100',\n",
              "    'M101',\n",
              "    'M104',\n",
              "    'M11',\n",
              "    'M2',\n",
              "    'M3',\n",
              "    'M4',\n",
              "    'M5'],\n",
              "   ['1', 'A', 'D', 'B', 'C'])),\n",
              " ((270, 441),\n",
              "  (['M101', 'M102', 'M15', 'M2', 'M31', 'M50', 'M57', 'Q101', 'Q32', 'Q60'],\n",
              "   ['4', '5', '6', 'N', 'Q', 'R', '6', 'E', 'M', 'F'])),\n",
              " ((60, 391), (['Bx12', 'Bx12-SBS', 'Bx26', 'Bx39', 'Bx8'], ['2', '5']))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [TO DO] G. Group the scores by the subway line and bus line so that we can compute the average by line\n",
        "Note that, one school may belong to multiple lines, so we need to somehow replicate the school score for each bus line. The output of this step should be in the key/value pair format with the key is the line, and the value is the average score.\n",
        "\n",
        "To make it easier, please store the bus and subway data in `G_bus` and `G_subway` respectively."
      ],
      "metadata": {
        "id": "SD__1QUdH49b"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lix8a2ITpn_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "99b1065f-e8dd-4823-f6b0-70c9cc1b51d6"
      },
      "source": [
        "# Creatting a function to count average score.\n",
        "def cal_avg(data):\n",
        "    return data.map(lambda x: (x[1], (x[0][1] * x[0][0], x[0][0]))) \\\n",
        "               .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1])) \\\n",
        "               .mapValues(lambda x: x[0]/x[1])\n",
        "\n",
        "# Create G_bus and G_subway here as RDDs\n",
        "G_bus = cal_avg(F.flatMapValues(lambda x: x[0]))\n",
        "G_subway = cal_avg(F.flatMapValues(lambda x: x[1]))\n",
        "\n",
        "## DO NOT EDIT BELOW\n",
        "display(G_bus.take(5))\n",
        "display(G_subway.take(5))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('B44', 465.0336676217765),\n",
              " ('Q66', 461.55149181905676),\n",
              " ('Q69', 444.03056234718827),\n",
              " ('M100', 427.83587443946186),\n",
              " ('M3', 432.531451213472)]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('N', 493.5055292259084),\n",
              " ('4', 495.29238227146817),\n",
              " ('L', 426.3222871994802),\n",
              " ('J', 439.1299656694458),\n",
              " ('B', 491.95760524225574)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### H. Get the line with the highest score"
      ],
      "metadata": {
        "id": "JwaJJH0QJ-us"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ycWIARH7ppUa",
        "outputId": "aad96adf-b325-45ab-8738-08aa5d4d2029"
      },
      "source": [
        "display(G_bus.max(lambda x: x[1]))\n",
        "display(G_subway.max(lambda x: x[1]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "('S1115', 612.2545811518324)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "('3', 513.4009556313994)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6oVbv7nqD2q"
      },
      "source": [],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsSA0dIMNznB"
      },
      "source": [
        "# Task 2 (5 points)\n",
        "You are asked to implement the Social Triangle example discussed in the MapReduce lecture but using Spark. Given the email dataset, please list all \"reciprocal\" relationships in the company. Recall that:\n",
        "\n",
        "If A emails B and B emails A, then A and B is *reciprocal*.\n",
        "\n",
        "If A emails B but B doesn’t email A, then A and B is *directed*.\n",
        "\n",
        "**Dataset:** We will use a subset of the open [Enron Email Dataset](https://www.cs.cmu.edu/~./enron/ \"Enron Email Dataset\"), which contains approximately 10,000 simplified email headers from the Enron Corporation. A subset of the data is available as **enron_mails_small.csv**\n",
        "\n",
        "The file contains 3 columns *Date*, *From*, and *To*. Their description is as follows:\n",
        "\n",
        "|Column name|Description|\n",
        "|--|--|\n",
        "|Date |The date and time of the email, in the format YYYY-MM-DD hh-mm-ss, <br />e.g. \"1998-10-30 07:43:00\" |\n",
        "|From |The sender email address, <br />e.g. \"mark.taylor@enron.com\" |\n",
        "|To | A list of recipients' email addresses separated by semicolons ';', <br />e.g. \"jennifer.fraser@enron.com;jeffrey.hodge@enron.com\" |\n",
        "\n",
        "Note that, we only care about users employed by Enron, i.e. only relationships where email addresses end with *'@enron.com'*.\n",
        "\n",
        "The expected output is also provided below. For each reciprocal relationship, please output a tuple consisting of two strings (or a two column dataframe), e.g. **('Jane Doe', 'John Doe')**. The names should be presented in the lexical order, i.e. there will not be a `('John Doe','Jane Doe')` since `'Jane'` is ordered before `'John'`.\n",
        "\n",
        "Though the dataset only contains email addresses, not actual names, we're assuming that the email aliases were created based on their name. For example:\n",
        "\n",
        "|Email Address|Converted Name|\n",
        "|--|--|\n",
        "|mark.taylor@enron.com|Mark Taylor|\n",
        "|alan.aronowitz@enron.com|Alan Aronowitz|\n",
        "|marc.r.cutler@enron.com|Marc R Cutler|\n",
        "|hugh@enron.com|Hugh|"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You can choose to use either Spark's RDD or Spark's DataFrame in this task.\n",
        "Regardless of your choice, you must perform all computation using Sparks' transformations, i.e. data must be read directly from the input file into your RDD and DataFrame and stay there for the entire computation."
      ],
      "metadata": {
        "id": "YgBTISnqrV4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using RDD"
      ],
      "metadata": {
        "id": "iaEgcHgqpW9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mail_csv = 'enron_mails_small.csv'\n",
        "mail = sc.textFile(mail_csv, use_unicode=True).cache()\n",
        "list(enumerate(mail.first().split(',')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ4wZhImQ5GI",
        "outputId": "0272b90b-1c18-48fa-866a-e81757ad460e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'Date'), (1, 'From'), (2, 'To')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extractEmails(partId, rows):\n",
        "    if partId == 0:\n",
        "        next(rows)\n",
        "    reader = csv.reader(rows)\n",
        "    for fields in reader:\n",
        "        if len(fields) == 2:\n",
        "            continue\n",
        "        From, To = fields[1], fields[2]\n",
        "        if not (From.endswith('@enron.com') and To.endswith('@enron.com')):\n",
        "            continue\n",
        "        if any(char.isdigit() for char in From):\n",
        "            continue\n",
        "        # Splitting \"To\" email addresses using \";\" separator and filter for Enron emails\n",
        "        To_list = [to_email.strip() for to_email in To.split(';') if to_email.strip().endswith('@enron.com') and not any(char.isdigit() for char in to_email.strip())]\n",
        "        for to_email in To_list:\n",
        "            yield (From, to_email)\n",
        "\n",
        "A2 = mail.mapPartitionsWithIndex(extractEmails)\n",
        "A2.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTo6p0XaQ_NF",
        "outputId": "ef49161d-024e-4ac8-a49f-a01b9273d8f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mark.taylor@enron.com', 'shari.stack@enron.com'),\n",
              " ('mark.taylor@enron.com', 'yao.apasu@enron.com'),\n",
              " ('mark.taylor@enron.com', 'paul.simons@enron.com'),\n",
              " ('mark.taylor@enron.com', 'justin.boyd@enron.com'),\n",
              " ('mark.taylor@enron.com', 'tana.jones@enron.com')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_name(email):\n",
        "    return tuple(map(lambda x: x.split('@')[0].replace('.', ' ').title(), email))\n",
        "B2= A2.map(lambda x: extract_name(x))\n",
        "B2.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgq9RWNiQ_QU",
        "outputId": "a158e717-0d39-4255-917e-2a52178088b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mark Taylor', 'Shari Stack'),\n",
              " ('Mark Taylor', 'Yao Apasu'),\n",
              " ('Mark Taylor', 'Paul Simons'),\n",
              " ('Mark Taylor', 'Justin Boyd'),\n",
              " ('Mark Taylor', 'Tana Jones')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates\n",
        "C2 = B2.distinct()\n",
        "C2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Brl3JaRUQ_Tb",
        "outputId": "b2428c2a-c58b-42a6-d21f-16523c3b8c98"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3390"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by the From column\n",
        "D2 = C2.sortByKey()\n",
        "D2.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvwWcTfPQ_Wp",
        "outputId": "723013e5-a24f-4777-e80a-5bbe8fb54328"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Andrew Lewis', 'Derek Davies'),\n",
              " ('Angela Mcculloch', 'Ione Irvine'),\n",
              " ('Angela Mcculloch', 'Attila Pazmandi'),\n",
              " ('Angela Mcculloch', 'Dan Dietrich'),\n",
              " ('Angela Mcculloch', 'Tara Sweitzer')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def interactions(names):\n",
        "    sorted_names = tuple(sorted(names))\n",
        "    return (sorted_names, 1)\n",
        "\n",
        "# Countting the occurrences of each email pair\n",
        "E2 = D2.map(lambda x: interactions(x)) \\\n",
        "       .reduceByKey(lambda x, y: x + y)\n",
        "E2.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-fBRGz_Q_ZW",
        "outputId": "280f13f2-b555-4a32-bc3b-8c86f3d3833a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('Andrew Lewis', 'Derek Davies'), 1),\n",
              " (('Angela Mcculloch', 'Ione Irvine'), 1),\n",
              " (('Angela Mcculloch', 'Attila Pazmandi'), 1),\n",
              " (('Angela Mcculloch', 'Dan Dietrich'), 1),\n",
              " (('Angela Mcculloch', 'Tara Sweitzer'), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code to read and process data into rddTask2\n",
        "rddTask2 = E2.filter(lambda x: x[1] >= 2) \\\n",
        "       .map(lambda x: x[0]) \\\n",
        "       .sortByKey()\n",
        "\n",
        "# DO NOT EDIT BELOW\n",
        "rddTask2.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLZGWB8TQ_cO",
        "outputId": "f1bcb621-042b-46e9-9ad6-a8fea2305f73"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Brenda Whitehead', 'Elizabeth Sager'),\n",
              " ('Carol Clair', 'Sara Shackleton'),\n",
              " ('Carol Clair', 'Debra Perlingiere'),\n",
              " ('Carol Clair', 'Tana Jones'),\n",
              " ('Carol Clair', 'Mark Taylor'),\n",
              " ('Carol Clair', 'Richard Sanders'),\n",
              " ('Debra Perlingiere', 'Kevin Ruscitti'),\n",
              " ('Drew Fossum', 'Susan Scott'),\n",
              " ('Elizabeth Sager', 'Janette Elbertson'),\n",
              " ('Elizabeth Sager', 'Mark Haedicke'),\n",
              " ('Elizabeth Sager', 'Mark Taylor'),\n",
              " ('Elizabeth Sager', 'Richard Sanders'),\n",
              " ('Eric Bass', 'Susan Scott'),\n",
              " ('Fletcher Sturm', 'Greg Whalley'),\n",
              " ('Fletcher Sturm', 'Sally Beck'),\n",
              " ('Gerald Nemec', 'Susan Scott'),\n",
              " ('Grant Masson', 'Vince Kaminski'),\n",
              " ('Greg Whalley', 'Richard Sanders'),\n",
              " ('Janette Elbertson', 'Mark Taylor'),\n",
              " ('Janette Elbertson', 'Richard Sanders'),\n",
              " ('Liz Taylor', 'Mark Haedicke'),\n",
              " ('Mark Haedicke', 'Mark Taylor'),\n",
              " ('Mark Haedicke', 'Richard Sanders'),\n",
              " ('Mark Haedicke', 'Twanda Sweet'),\n",
              " ('Mark Haedicke', 'Michelle Cash'),\n",
              " ('Mark Taylor', 'Tana Jones'),\n",
              " ('Mark Taylor', 'Sara Shackleton'),\n",
              " ('Michelle Cash', 'Twanda Sweet'),\n",
              " ('Pinnamaneni Krishnarao', 'Vince Kaminski'),\n",
              " ('Richard Sanders', 'Sara Shackleton'),\n",
              " ('Rosalee Fleming', 'Steven Kean'),\n",
              " ('Sara Shackleton', 'Tana Jones'),\n",
              " ('Shirley Crenshaw', 'Vince Kaminski'),\n",
              " ('Stinson Gibner', 'Vince Kaminski'),\n",
              " ('Vasant Shanbhogue', 'Vince Kaminski')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UQiapDwhRXAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSee1IlmRXGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using DataFrame"
      ],
      "metadata": {
        "id": "5ZbjfmuapTkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code to read and process data into dfTask2\n",
        "dfTask2 = ...\n",
        "\n",
        "# DO NOT EDIT BELOW\n",
        "dfTask2.show(n=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3205df6c-247d-495a-98f1-95797216e8f2",
        "id": "5MRzBNExpFxD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+\n",
            "|            Person 1|         Person 2|\n",
            "+--------------------+-----------------+\n",
            "|    Brenda Whitehead|  Elizabeth Sager|\n",
            "|         Carol Clair|Debra Perlingiere|\n",
            "|         Carol Clair|      Mark Taylor|\n",
            "|         Carol Clair|  Richard Sanders|\n",
            "|         Carol Clair|  Sara Shackleton|\n",
            "|         Carol Clair|       Tana Jones|\n",
            "|   Debra Perlingiere|   Kevin Ruscitti|\n",
            "|         Drew Fossum|      Susan Scott|\n",
            "|     Elizabeth Sager|Janette Elbertson|\n",
            "|     Elizabeth Sager|    Mark Haedicke|\n",
            "|     Elizabeth Sager|      Mark Taylor|\n",
            "|     Elizabeth Sager|  Richard Sanders|\n",
            "|           Eric Bass|      Susan Scott|\n",
            "|      Fletcher Sturm|     Greg Whalley|\n",
            "|      Fletcher Sturm|       Sally Beck|\n",
            "|        Gerald Nemec|      Susan Scott|\n",
            "|        Grant Masson|   Vince Kaminski|\n",
            "|        Greg Whalley|  Richard Sanders|\n",
            "|   Janette Elbertson|      Mark Taylor|\n",
            "|   Janette Elbertson|  Richard Sanders|\n",
            "|          Liz Taylor|    Mark Haedicke|\n",
            "|       Mark Haedicke|      Mark Taylor|\n",
            "|       Mark Haedicke|    Michelle Cash|\n",
            "|       Mark Haedicke|  Richard Sanders|\n",
            "|       Mark Haedicke|     Twanda Sweet|\n",
            "|         Mark Taylor|  Sara Shackleton|\n",
            "|         Mark Taylor|       Tana Jones|\n",
            "|       Michelle Cash|     Twanda Sweet|\n",
            "|Pinnamaneni Krish...|   Vince Kaminski|\n",
            "|     Richard Sanders|  Sara Shackleton|\n",
            "|     Rosalee Fleming|      Steven Kean|\n",
            "|     Sara Shackleton|       Tana Jones|\n",
            "|    Shirley Crenshaw|   Vince Kaminski|\n",
            "|      Stinson Gibner|   Vince Kaminski|\n",
            "|   Vasant Shanbhogue|   Vince Kaminski|\n",
            "+--------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}